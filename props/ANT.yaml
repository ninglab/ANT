adaptor_layers : [768,256]
train_stage : 'inductive_ft'

tf_fusion : 'SFusion'
temperature : 0.07
initializer_range: 0.02
n_exps : 8
hidden_size : 256
noise : True
batch_size : 2048
optim : 'Adam'

adaptor_dropout_prob : 0.2
hidden_dropout_prob : 0.5
attn_dropout_prob : 0.5

n_layers_rec : 2
n_heads_rec : 2
hidden_act : 'gelu'
layer_norm_eps : 1e-8

n_layers_fusion : 2
n_heads_fusion : 2
layers_ds : 2
pooling_ds : 'Mean'
